{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJuQw66t8YHN9PVH6WeWPD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CWaiwit/MADT7202-SNA_Mockup-red01/blob/main/SNA_mockup_03_red01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fue-O2_EiKIF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd;\n",
        "import numpy as np;"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Mockup Class"
      ],
      "metadata": {
        "id": "RudA5Ujl4bcf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Mock up affiliation network"
      ],
      "metadata": {
        "id": "lFYPTJa3XI-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MockupAffNW:\n",
        "    RAND_SEED = 94232;\n",
        "    N_USERS = 75;\n",
        "    N_EXPRESSION = 7501;\n",
        "\n",
        "    users:pd.DataFrame = None;\n",
        "    interests:pd.DataFrame = None;\n",
        "    user_interest:pd.DataFrame = None;\n",
        "    linkages:pd.DataFrame = None;\n",
        "\n",
        "    def set_param(self, rand_seed:int=94232, n_user:int=75, n_expr=7501):\n",
        "        self.RAND_SEED=rand_seed;\n",
        "        self.N_USERS=n_user;\n",
        "        self.N_EXPRESSION=n_expr;\n",
        "        pass;\n",
        "\n",
        "    def get_interests(self) -> pd.DataFrame:\n",
        "        if self.interests is None:\n",
        "            interest = [\n",
        "                {'interest':'Love', 'topic':'Love'},\n",
        "                {'interest':'Wealth', 'topic':'Wealth'},\n",
        "                {'interest':'Career', 'topic':'Career'},\n",
        "                {'interest':'Health', 'topic':'Others'},\n",
        "                {'interest':'Birth', 'topic':'Others'},\n",
        "                {'interest':'Eduction', 'topic':'Others'},\n",
        "                {'interest':'Romance', 'topic':'non-mu-topic'},\n",
        "                {'interest':'Pet', 'topic':'non-mu-topic'},\n",
        "                {'interest':'Lottery', 'topic':'non-mu-topic'},\n",
        "                {'interest':'Music', 'topic':'non-mu-topic'},\n",
        "                {'interest':'Weather', 'topic':'non-mu-topic'},\n",
        "                {'interest':'News', 'topic':'non-mu-topic'},\n",
        "                {'interest':'Television', 'topic':'non-mu-topic'},\n",
        "                {'interest':'Leisure', 'topic':'non-mu-topic'}\n",
        "            ];\n",
        "            self.interests = pd.DataFrame(interest);\n",
        "        return self.interests.loc[:];\n",
        "    \n",
        "    def get_users(self) -> pd.DataFrame:\n",
        "        if self.users is None:\n",
        "            interests:pd.DataFrame = self.get_interests();\n",
        "\n",
        "            np.random.seed(self.RAND_SEED);\n",
        "            df:pd.DataFrame = pd.DataFrame(['UID'+str(x+1).zfill(4) for x in range(self.N_USERS)], columns=['uid']);\n",
        "\n",
        "            # Probability of being detected in users network\n",
        "            df['p_obsrv'] = np.random.normal(0.5, 0.125, len(df.index));\n",
        "            obsrv_total = df['p_obsrv'].sum()\n",
        "            df['p_obsrv'] = df['p_obsrv']/obsrv_total;\n",
        "\n",
        "            # Generate user's interest\n",
        "            df['n_interest'] = np.random.randint(3, 7, len(df.index));\n",
        "            df['n_interest'] = df['n_interest'].round();\n",
        "            df['interests'] = df['n_interest'].apply(lambda x: np.random.choice(interests['interest'], int(x), replace=False ) );\n",
        "            df['interests'] = df['interests'].apply(','.join);\n",
        "            df.drop(columns=['n_interest'], inplace=True);\n",
        "\n",
        "            self.users = df;\n",
        "        return self.users.loc[:];\n",
        "\n",
        "    def get_user_interest(self) -> pd.DataFrame:\n",
        "        if self.user_interest is None:\n",
        "            users = self.get_users();\n",
        "            interest = self.get_interests();\n",
        "            \n",
        "            users['interests'] = users['interests'].str.split(',');\n",
        "            users['x'] = users.apply(lambda x: [{'uid':x.uid, 'interest':i} for i in x.interests ], axis='columns');\n",
        "            df:pd.DataFrame = pd.DataFrame(users['x'].explode().to_list());\n",
        "\n",
        "            # self.user_interest = pd.DataFrame(users['x'].explode().to_list());\n",
        "            df = df.set_index('interest').join(interest.set_index('interest'));\n",
        "            df.reset_index('interest', inplace=True);\n",
        "\n",
        "            df.sort_values(['uid', 'interest', 'topic'], ignore_index=True, inplace=True);\n",
        "\n",
        "            self.user_interest = df[['uid', 'interest', 'topic']];\n",
        "        return self.user_interest.loc[:];\n",
        "\n",
        "    def get_linkage(self) -> pd.DataFrame:\n",
        "        if self.linkages is None:\n",
        "            users = self.get_users();\n",
        "            users['interests'] = users['interests'].str.split(',');\n",
        "\n",
        "            uxi:pd.DataFrame = self.get_user_interest();\n",
        "            ixu:pd.DataFrame = uxi.groupby('interest')['uid'].apply(set).reset_index();\n",
        "\n",
        "            # generate src of random linkage\n",
        "            np.random.seed(self.RAND_SEED);\n",
        "            df:pd.DataFrame = pd.DataFrame(np.random.choice(users['uid'], self.N_EXPRESSION, p=users['p_obsrv']), columns=['uid_src']);\n",
        "            \n",
        "            # random linkage-affiliation\n",
        "            users.set_index('uid', inplace=True);\n",
        "            df['interest'] = df['uid_src'].apply(lambda x: np.random.choice(users.at[x, 'interests']));\n",
        "            users.reset_index(names=['uid'], inplace=True);\n",
        "\n",
        "            # random affiliated-target\n",
        "            ixu.set_index('interest', inplace=True);\n",
        "            df['uid_tgt_ls'] = df.apply(lambda x: sorted(ixu.at[x.interest, 'uid'] - {x.uid_src}), axis='columns');\n",
        "            df['uid_tgt_ls'] = df['uid_tgt_ls'].apply(list);\n",
        "            ixu.reset_index(names=['interest'], inplace=True);\n",
        "            df['uid_tgt_p_ls'] = df.apply(lambda x: users[users['uid'].isin(x['uid_tgt_ls'])]['p_obsrv'].to_list(), axis='columns');\n",
        "            df['uid_tgt_p_total'] = df['uid_tgt_p_ls'].apply(sum);\n",
        "            df['uid_tgt_p_ls'] = df.apply(lambda x: [i/x.uid_tgt_p_total for i in x.uid_tgt_p_ls], axis='columns');\n",
        "            df['uid_tgt'] = df.apply(lambda x: np.random.choice(x.uid_tgt_ls, p=x.uid_tgt_p_ls), axis='columns');\n",
        "            df.drop_duplicates(subset=['uid_src', 'interest', 'uid_tgt'], inplace=True);\n",
        "            df.drop(columns=['uid_tgt_ls', 'uid_tgt_p_ls','uid_tgt_p_total'], inplace=True);\n",
        "            \n",
        "            df.sort_values(by=['uid_src','uid_tgt', 'interest'], ignore_index=True, inplace=True);\n",
        "\n",
        "            self.linkages = df[['uid_src','uid_tgt', 'interest']];\n",
        "        return self.linkages.loc[:];"
      ],
      "metadata": {
        "id": "kvDsB5zlCksX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Mock up SNA"
      ],
      "metadata": {
        "id": "BYRsabBIXQ_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MockupSNA03:\n",
        "    RAND_SEED = 94232;\n",
        "    N_USERS = 75;\n",
        "    N_INFLUENCERS = 25;\n",
        "    N_BRANDS = 4;\n",
        "    N_POST = 1501;\n",
        "    N_INTERACT_LIKE_MIN = 100;\n",
        "    N_INTERACT_LIKE_MAX = 200;\n",
        "    N_INTERACT_MIN = 70;\n",
        "    N_INTERACT_MAX = 156;\n",
        "    N_RAND_FOLLOW_MIN = 250;\n",
        "    N_RAND_FOLLOW_MAX = 500;\n",
        "\n",
        "\n",
        "\n",
        "    users: pd.DataFrame = None;\n",
        "    user_x_user: pd.DataFrame = None;\n",
        "    brands: pd.DataFrame = None;\n",
        "    pages: pd.DataFrame = None;\n",
        "    brand_x_page: pd.DataFrame =None;\n",
        "\n",
        "\n",
        "    user_x_page: pd.DataFrame = None;\n",
        "\n",
        "    post_behavior: pd.DataFrame = None;\n",
        "    posts: pd.DataFrame = None;\n",
        "    post_interaction: pd.DataFrame = None;\n",
        "    \n",
        "    def set_param(self, seed:int=94232,\n",
        "            n_like_min:int=100, n_like_max:int=200,\n",
        "            n_intrx_min:int=70, n_intrx_max:int=156,\n",
        "            n_follow_min:int=250, n_follow_max:int=500):\n",
        "        self.RAND_SEED = seed;\n",
        "        self.N_INTERACT_LIKE_MIN = n_like_min;\n",
        "        self.N_INTERACT_LIKE_MAX = n_like_max;\n",
        "        self.N_INTERACT_MIN = n_intrx_min;\n",
        "        self.N_INTERACT_MAX = n_intrx_max;\n",
        "        self.N_RAND_FOLLOW_MIN = n_follow_min;\n",
        "        self.N_RAND_FOLLOW_MAX = n_follow_max;\n",
        "        pass;\n",
        "\n",
        "    def gen_model(self):\n",
        "        '''Generat all data at once'''\n",
        "        self.get_users();\n",
        "        self.get_user_x_user();\n",
        "        self.get_brands()\n",
        "        self.get_pages();\n",
        "        self.get_brand_x_page();\n",
        "        self.get_post_behavior();\n",
        "        self.get_posts();\n",
        "        self.get_post_interaction();\n",
        "        self.get_user_x_page();\n",
        "        pass;\n",
        "    \n",
        "    def init_aff_network(self, n_expr:int=7501, aff:MockupAffNW=None):\n",
        "        if aff is None:\n",
        "            aff = MockupAffNW();\n",
        "            aff.set_param(rand_seed=self.RAND_SEED, n_user=self.N_USERS, n_expr=n_expr);\n",
        "        \n",
        "        users = aff.get_users();\n",
        "        users['interests'] = users['interests'].str.split(',');\n",
        "\n",
        "        # generate user and preference\n",
        "        interest = aff.get_interests();\n",
        "        interest.set_index('interest', inplace=True);\n",
        "        users['topics'] = users['interests'].apply(lambda x: [ interest.at[i, 'topic'] for i in x]);\n",
        "        interest.reset_index(names=['interest'], inplace=True);\n",
        "        users['uxt'] = users[['uid', 'topics']].apply(lambda x: [{'uid':x.uid, 'topic':i} for i in x.topics], axis='columns');\n",
        "        uxt:pd.DataFrame = pd.DataFrame(users['uxt'].explode().to_list());\n",
        "        uxt['n'] = 1;\n",
        "        uxt = uxt.groupby(['uid', 'topic'])[['n']].sum().reset_index();\n",
        "        uxt_total = uxt.groupby(['uid'])['n'].sum();\n",
        "        uxt = uxt.set_index('uid').join(uxt_total, rsuffix='_total');\n",
        "        uxt['topic_p'] = uxt['n']/uxt['n_total'];\n",
        "        tmp = uxt.groupby('uid')['topic_p'].apply(list).reset_index();\n",
        "        uxt = uxt.groupby('uid')['topic'].apply(list).reset_index();\n",
        "        uxt = uxt.set_index('uid').join(tmp.set_index('uid'));\n",
        "        uxt.reset_index(names='uid', inplace=True);\n",
        "        uxt['topic'] = uxt['topic'].apply(','.join);\n",
        "        uxt['topic_p'] = uxt['topic_p'].apply(lambda x: [str(i) for i in x]);\n",
        "        uxt['topic_p'] = uxt['topic_p'].apply(','.join);\n",
        "        self.users = uxt;\n",
        "\n",
        "        # generate user-linkage\n",
        "        links = aff.get_linkage()\n",
        "        links = links.set_index('interest').join(interest.set_index('interest'));\n",
        "        links.reset_index(drop=True, inplace=True);\n",
        "        links['set'] = links.apply(lambda x: sorted({x.uid_src, x.uid_tgt}), axis='columns');\n",
        "        links['set'] = links['set'].apply('|'.join);\n",
        "        links = links.groupby(['set'])['topic'].apply(set).reset_index();\n",
        "        links['set'] = links['set'].str.split('|');\n",
        "        links['source'] = links['set'].apply(lambda x: x[0]);\n",
        "        links['target'] = links['set'].apply(lambda x: x[1]);\n",
        "        links['linkage'] = links['topic'].apply(','.join);\n",
        "        links.drop(columns=['set', 'topic'], inplace=True);\n",
        "        # links.drop(columns=['set', 'topic', 'linkage'], inplace=True);\n",
        "        # links.drop_duplicates(inplace=True);\n",
        "        self.user_x_user = links;\n",
        "    \n",
        "    def get_users(self):\n",
        "        '''Generate fb users'''\n",
        "        if self.users is None:\n",
        "            df:pd.DataFrame = pd.DataFrame(['UID'+str(x+1).zfill(4) for x in range(self.N_USERS)], columns=['uid']);\n",
        "            self.users = df;\n",
        "        return self.users.loc[:];\n",
        "    \n",
        "    def get_user_x_user(self) -> pd.DataFrame: return self.user_x_user.loc[:];\n",
        "\n",
        "    def get_brands(self) -> pd.DataFrame:\n",
        "        if self.brands is None:\n",
        "            ls = [\n",
        "                { 'id': 'Leila', 'type': 'org-brand', 'mrkt_value': 30 },\n",
        "                { 'id': 'Ravipa', 'type': 'cmpt-brand', 'mrkt_value': 23 },\n",
        "                { 'id': 'Hermanstones', 'type':'cmpt-brand', 'mrkt_value': 1.5 },\n",
        "                { 'id': 'Maron', 'type':'cmpt-brand', 'mrkt_value': 1 }\n",
        "            ];\n",
        "            self.brands = pd.DataFrame(ls);\n",
        "        return self.brands.loc[:];\n",
        "    \n",
        "    def get_pages(self) -> pd.DataFrame:\n",
        "        '''Generate list of fb page - include Mu brands'''\n",
        "        if self.pages is None:\n",
        "            ls = [\n",
        "                {'id': 'Leila-page', 'type': 'org-page', 'brand': 'Leila'},\n",
        "                {'id': 'Ravipa-page', 'type': 'cmpt-page', 'brand': 'Ravipa'},\n",
        "                {'id': 'Hermanstones-page', 'type': 'cmpt-page', 'brand':'Hermanstones'},\n",
        "                {'id': 'Maron-page', 'type': 'cmpt-page', 'brand':'Maron'},\n",
        "            ] + [ {'id': 'PG'+str(i+1).zfill(3), 'type': 'inf-page' } for i in range(25)];\n",
        "\n",
        "            np.random.seed(self.RAND_SEED);\n",
        "            np.random.shuffle(ls);\n",
        "            df:pd.DataFrame = pd.DataFrame(ls);\n",
        "\n",
        "            self.pages = df[['id', 'type', 'brand']];\n",
        "        return self.pages.loc[:];\n",
        "\n",
        "    def get_brand_x_page(self) -> pd.DataFrame:\n",
        "        '''Organically generate brand-to-page relationship:\n",
        "        - One brand may support many influencers\n",
        "        - One influencer may advertise many brand\n",
        "        - Stregth Scale represents the strength of brand's influence over influencer (str_scale)\n",
        "        - [Control] No relation between mu-marketing-player: brand and competitor\n",
        "        - [Control] No relation between influencers'''\n",
        "        if self.brand_x_page is None:\n",
        "            df: pd.DataFrame = self.get_pages();\n",
        "            \n",
        "            # Random relation brand-influencer\n",
        "            ## Random brand propability in relation\n",
        "            np.random.seed(self.RAND_SEED);\n",
        "            ls:list = self.get_brands().id.to_list() +['others'];\n",
        "            ls_p = np.random.normal( 0.5, 0.125, len(ls));\n",
        "            # ls_p = np.random.normal( 0.5, 0.5, len(ls));\n",
        "            # ls_p = np.absolute(ls_p);\n",
        "            p_total = ls_p.sum();\n",
        "            ls_p = ls_p/p_total;\n",
        "            ls_p = list(ls_p)\n",
        "\n",
        "            ## Random page probability in relation\n",
        "            influencer = df[df['type']=='inf-page'][['id']].loc[:]\n",
        "            # influencer['p'] = np.random.normal( 0.5, 0.125, len(influencer.index));\n",
        "            influencer['p'] = np.random.normal( 0.5, 0.5, len(influencer.index));\n",
        "            influencer['p'] = influencer['p'].abs()\n",
        "            p_total = influencer.p.sum();\n",
        "            influencer['p'] = influencer['p']/p_total;\n",
        "\n",
        "            n = 300;\n",
        "            src = np.random.choice(ls, n, p=ls_p);\n",
        "            tgt = np.random.choice(influencer.id, n , p=influencer.p);\n",
        "            links = pd.DataFrame({'source':src, 'target':tgt});\n",
        "            links.drop(links[links.source=='others'].index, inplace=True);\n",
        "\n",
        "            # Calculate relatioship strength\n",
        "            ## Sum number of connections as strength\n",
        "            links['n'] = 1;\n",
        "            links = links.groupby(['source', 'target']).n.sum().reset_index(['source', 'target']);\n",
        "            links['id'] = links.index + 1;\n",
        "\n",
        "            ## Convert to proportion of strength toward sponsor brand - strength scale.\n",
        "            links_w = links.groupby('target').n.sum().reset_index().set_index('target');\n",
        "            links = links.set_index('target').join(links_w, rsuffix='_total').reset_index('target').sort_values('id');\n",
        "            links['str_scale'] = links['n']/links['n_total'];\n",
        "\n",
        "            self.brand_x_page = links[['id', 'source', 'target', 'str_scale']];\n",
        "        return self.brand_x_page.loc[:];\n",
        "\n",
        "    def get_post_behavior(self) -> pd.DataFrame:\n",
        "        '''Generate posting behavior of pages:\n",
        "        - Page's posting is depended-on probability (post_p)\n",
        "        - Influencer may or may not post mu-content - depended-on proability (mu_p)\n",
        "        - Strength Scale of brands influence over the ratio of influencer's mu-content (str_scale)'''\n",
        "        if self.post_behavior is None:\n",
        "            pgs:pd.DataFrame = self.get_pages();\n",
        "            bxp:pd.DataFrame = self.get_brand_x_page();\n",
        "\n",
        "            np.random.seed(self.RAND_SEED);\n",
        "\n",
        "            # List of sponsor and strength scale\n",
        "            ## make list of sponsor sources\n",
        "            bxp__tgt_grp = bxp.groupby('target');\n",
        "            page_sponsor = bxp__tgt_grp['source'].apply(list).reset_index();\n",
        "            page_sponsor.set_index('target',inplace=True);\n",
        "\n",
        "            ## make list of sponsor strength scale\n",
        "            page_support_sc = bxp__tgt_grp.str_scale.apply(list).reset_index();\n",
        "            page_support_sc.set_index('target',inplace=True);\n",
        "            page_sponsor = page_sponsor.join(page_support_sc);\n",
        "\n",
        "            ## convert list to string - for data prep\n",
        "            page_sponsor['source'] = page_sponsor['source'].apply(','.join);\n",
        "            page_sponsor['str_scale'] = page_sponsor['str_scale'].apply(lambda x: [ str(i) for i in x ]);\n",
        "            page_sponsor['str_scale'] = page_sponsor['str_scale'].apply(','.join);\n",
        "\n",
        "            # Random mu-post probability\n",
        "            page_sponsor['mu_p'] = np.random.normal(0.5, 0.076, len(page_sponsor.index));\n",
        "            page_sponsor['mu_p'] = page_sponsor['mu_p'].round(2);\n",
        "\n",
        "            # Assign page's post behavior\n",
        "            ## Join page with sponsors and sponsors' scale\n",
        "            pgs = pgs.set_index('id').join(page_sponsor);\n",
        "            pgs. reset_index(inplace=True);\n",
        "\n",
        "            ## Assign brand to mu-player's page and non-mu-brand page\n",
        "            pgs['source'] = pgs[['brand', 'type', 'source']].apply(lambda x: x.brand if x['type'] != 'inf-page' else x.source, axis='columns');\n",
        "            pgs['source'] = pgs['source'].apply(lambda x: 'other' if pd.isna(x) else x);\n",
        "\n",
        "            ## Assign str_scale to mu-player's page and non-mu-brand page\n",
        "            pgs['str_scale'] = pgs[['type', 'str_scale']].apply(lambda x: '1.0' if x['type'] != 'inf-page' else x.str_scale, axis='columns');\n",
        "            pgs['str_scale'] = pgs['str_scale'].fillna('0.0');\n",
        "\n",
        "            ## Assign mu-post probability to mu-player's page and non-mu-brand page\n",
        "            pgs['mu_p'] = pgs[['type', 'mu_p']].apply(lambda x: 1.0 if x['type'] !='inf-page' else x.mu_p, axis='columns');\n",
        "            pgs['mu_p'] = pgs['mu_p'].fillna(0.0);\n",
        "\n",
        "            ## Assign post distribution probability\n",
        "            post_p_ls = np.random.normal(0.5, 0.25, len(pgs.index));\n",
        "            post_p_ls = post_p_ls - post_p_ls.min();\n",
        "            post_p_ls = post_p_ls/post_p_ls.sum();\n",
        "            pgs['post_p'] = post_p_ls;\n",
        "\n",
        "            self.post_behavior = pgs[['id', 'type', 'source', 'str_scale', 'mu_p', 'post_p']];\n",
        "        return self.post_behavior.loc[:];\n",
        "\n",
        "    def get_posts(self):\n",
        "        if self.posts is None:\n",
        "            '''Generate posts:\n",
        "            - Page's posts generate ramdomly - depended on page's posting probability (post_p)\n",
        "            - Page's posts possibly be mu-content -depended on page's mu probability (mu_p)\n",
        "            - [Control] MU-content is labeled to \"Love\", \"Wealth\", \"Career\", or \"Others\"\n",
        "            - [Control] Non-mu-content will not represent any mu-topic nor mu-brands - defined as \"non-mu-topic\" and \"non-mu-brand\" respectively\n",
        "            '''\n",
        "            beh = self.get_post_behavior();\n",
        "            np.random.seed(self.RAND_SEED);\n",
        "\n",
        "            # Random post ower - page\n",
        "            posts = pd.DataFrame(np.random.choice(beh.id, self.N_POST, p=beh.post_p), columns=['page_id']);\n",
        "            posts['id'] = posts.index+1;\n",
        "            posts['id'] = posts['id'].apply(lambda x: 'POST'+str(x).zfill(6))\n",
        "\n",
        "            # Random flag mu-product post\n",
        "            beh.set_index('id', inplace=True);\n",
        "            posts = posts.set_index('page_id').join(beh[['mu_p']]);\n",
        "            posts.reset_index(names=['page_id'], inplace=True);\n",
        "            posts['mu_f'] = posts['mu_p'].apply(lambda x: True if x==1 else False if x==0 else np.random.choice([True, False], 1, [x, 1-x])[0] );\n",
        "\n",
        "            # Random brand of mu-content\n",
        "            posts_mu = posts[posts['mu_f']].loc[:];\n",
        "            posts_mu.set_index('page_id', inplace=True);\n",
        "            posts_mu = posts_mu.join(beh[['source', 'str_scale']]);\n",
        "            posts_mu.reset_index(names=['page_id'], inplace=True);\n",
        "            posts_mu['source'] = posts_mu['source'].str.split(',');\n",
        "            posts_mu['str_scale'] = posts_mu['str_scale'].str.split(',');\n",
        "            posts_mu['brand'] = posts_mu[['source', 'str_scale']].apply(\n",
        "                    lambda x: np.random.choice(x.source, 1, x.str_scale)[0],\n",
        "                    axis='columns');\n",
        "\n",
        "            # Random mu-topic\n",
        "            posts_mu['topic'] = np.random.choice(['Love', 'Wealth', 'Career', 'Others'], len(posts_mu.index));\n",
        "\n",
        "            # Join post - mu-topic\n",
        "            posts_mu.set_index('id', inplace=True);\n",
        "            posts.set_index('id', inplace=True);\n",
        "            posts = posts.join(posts_mu[['brand', 'topic']]);\n",
        "            posts.reset_index(names=['id'], inplace=True);\n",
        "\n",
        "            # Fill Nan with non-mu-topic, non-mu-brand\n",
        "            posts['topic'].fillna('non-mu-topic', inplace=True);\n",
        "            posts['brand'].fillna('non-mu-brand', inplace=True);\n",
        "\n",
        "            posts.sort_values('id', ignore_index=True, inplace=True);\n",
        "            self.posts = posts[['id', 'page_id', 'topic', 'brand']];\n",
        "        return self.posts.loc[:];\n",
        "\n",
        "    def get_user_x_page(self) -> pd.DataFrame:\n",
        "        '''Generate user's following page relationship\n",
        "        - Assume user proably follow a page if it has any post relevant to user's interest (Homophily)'''\n",
        "        if self.user_x_page is None:\n",
        "            users = self.get_users();\n",
        "            posts = self.get_posts();\n",
        "\n",
        "            # Topic-to-page probability\n",
        "            posts['n'] = 1;\n",
        "            txp = posts.groupby(['topic', 'page_id'])['n'].sum().reset_index();\n",
        "            txp_total = txp.groupby('topic')['n'].sum().reset_index();\n",
        "            txp_total.set_index('topic', inplace=True);\n",
        "            txp = txp.set_index('topic').join(txp_total, rsuffix='_total');\n",
        "            txp['p'] = txp['n']/txp['n_total'];\n",
        "            tmp = txp.groupby('topic')['p'].apply(list).reset_index();\n",
        "            txp = txp.groupby('topic')['page_id'].apply(list).reset_index();\n",
        "            txp = txp.set_index('topic').join(tmp.set_index('topic'));\n",
        "            txp.reset_index(names=['topic'], inplace=True);\n",
        "\n",
        "            # User-interest probability\n",
        "            users['topic'] = users['topic'].str.split(',');\n",
        "            users['topic_p'] = users['topic_p'].str.split(',');\n",
        "            users['topic_p'] = users['topic_p'].apply(lambda x: [float(i) for i in x]);\n",
        "            \n",
        "            # Generate sampling\n",
        "            np.random.seed(self.RAND_SEED);\n",
        "            n = np.random.randint(self.N_RAND_FOLLOW_MIN, self.N_RAND_FOLLOW_MAX);\n",
        "            follow:pd.DataFrame = pd.DataFrame( np.random.choice(users['uid'], n), columns=['uid']);\n",
        "\n",
        "            users.set_index('uid', inplace=True);\n",
        "            follow['interest'] = follow['uid'].apply(lambda x: np.random.choice( users.at[x,'topic'], p=users.at[x,'topic_p'] ) );\n",
        "            users.reset_index(names=['uid'], inplace=True);\n",
        "\n",
        "            txp.set_index('topic', inplace=True);\n",
        "            follow['page_id'] = follow['interest'].apply(lambda x: np.random.choice( txp.at[x,'page_id'], p=txp.at[x,'p'] ) );\n",
        "            txp.reset_index(names=['topic'], inplace=True);\n",
        "\n",
        "            follow.drop(columns=['interest'], inplace=True);\n",
        "            follow.drop_duplicates(inplace=True, ignore_index=True);\n",
        "            follow.sort_values(['uid', 'page_id'], ignore_index=True, inplace=True);\n",
        "            follow['id'] = follow.index + 1;\n",
        "            \n",
        "            self.user_x_page = follow[['id','uid','page_id']];\n",
        "        return self.user_x_page.loc[:];\n",
        "\n",
        "\n",
        "    def get_post_interaction(self) -> pd.DataFrame:\n",
        "        '''Random interaction\n",
        "        - page's post is open publicly - users able to interact regardless follow page or not, chance of following page is higher\n",
        "        - [Control] user interact post - like: once, commment: many-time, share: many-time'''\n",
        "\n",
        "        def fn(users:pd.DataFrame, posts:pd.DataFrame, n:int=5000):\n",
        "            '''Random interact-decisioning: user possibly interact if content from following page or interesting topic'''\n",
        "\n",
        "            df:pd.DataFrame = pd.DataFrame(np.random.choice(users['uid'], n, p=users['interact_p']), columns=['uid']);\n",
        "            df = df.set_index('uid').join(users.set_index('uid'));\n",
        "            df.reset_index(names=['uid'], inplace=True);\n",
        "            df['is_relevant'] = np.random.random(n);\n",
        "            df['is_relevant'] = df['is_relevant']>df['irrelevent_p'];\n",
        "            df['page_id'] = df['page_id'].astype(str);\n",
        "            df['page_id'] = df['page_id'].str.split(',');\n",
        "            df['page_id'] = df[['is_relevant', 'page_id']].apply(lambda x: np.random.choice(x.page_id) if x.is_relevant else None, axis='columns');\n",
        "            df['topic'] = df['topic'].astype(str);\n",
        "            df['topic'] = df['topic'].str.split(',');\n",
        "            df['topic'] = df[['is_relevant', 'topic']].apply(lambda x: np.random.choice(x.topic) if not x.is_relevant else None, axis='columns');\n",
        "\n",
        "            df['post_id'] = df[['page_id', 'topic']].apply(\n",
        "                    lambda x: posts[posts.page_id==x.page_id]['id'].to_list() if x.page_id is not None else posts[posts.topic==x.topic]['id'].to_list(),\n",
        "                    axis='columns');\n",
        "            df['post_id'] = df['post_id'].apply(lambda x: posts.id.to_list() if len(x)<1 else x);\n",
        "            df['post_id'] = df['post_id'].apply(np.random.choice);\n",
        "            return df.loc[:];\n",
        "\n",
        "    \n",
        "        if self.post_interaction is None:\n",
        "            users = self.get_users();\n",
        "            posts = self.get_posts();\n",
        "            uxpg = self.get_user_x_page();\n",
        "\n",
        "            np.random.seed(self.RAND_SEED);\n",
        "\n",
        "            # Random user's post-interaction behavior\n",
        "            uxpg['page_id'] = uxpg['page_id'].astype(str);\n",
        "            uxpg = uxpg.groupby('uid')['page_id'].apply(list).reset_index();\n",
        "            uxpg['page_id'] = uxpg['page_id'].apply(','.join)\n",
        "            users = users.set_index('uid').join(uxpg.set_index('uid'));\n",
        "            users.reset_index(names=['uid'], inplace=True);\n",
        "            users['irrelevent_p'] = np.random.normal(0.15, 0.0225, len(users.index));\n",
        "            users['interact_p'] = np.random.normal(0.5, 0.125, len(users.index));\n",
        "            t = users['interact_p'].sum();\n",
        "            users['interact_p'] = users['interact_p']/t;\n",
        "\n",
        "            # Like interaction\n",
        "            n = np.random.randint(self.N_INTERACT_LIKE_MIN, self.N_INTERACT_LIKE_MAX);\n",
        "            interact_like = fn(users=users, posts=posts, n=n);\n",
        "            interact_like = interact_like[['uid','post_id']].drop_duplicates();\n",
        "            interact_like['like'] = 1;\n",
        "\n",
        "            # Like interaction\n",
        "            n = np.random.randint(self.N_INTERACT_MIN, self.N_INTERACT_MAX);\n",
        "            interact_comment = fn(users=users, posts=posts, n=n);\n",
        "            interact_comment['comment'] = 1;\n",
        "            interact_comment = interact_comment.groupby(['uid','post_id'])['comment'].sum().reset_index();\n",
        "\n",
        "            # Share interaction\n",
        "            n = np.random.randint(self.N_INTERACT_MIN, self.N_INTERACT_MAX);\n",
        "            interact_share = fn(users=users, posts=posts, n=n);\n",
        "            interact_share['share'] = 1;\n",
        "            interact_share = interact_share.groupby(['uid','post_id'])['share'].sum().reset_index();\n",
        "\n",
        "            # Summary interaction\n",
        "            interact_comment = interact_comment.groupby(['uid', 'post_id']).comment.sum().reset_index()\n",
        "            interact_share = interact_share.groupby(['uid', 'post_id']).share.sum().reset_index()\n",
        "            interact = pd.concat([interact_like, interact_comment, interact_share]);\n",
        "            interact.fillna(0, inplace=True);\n",
        "\n",
        "            interact['id'] = interact.index+1;\n",
        "            interact['id'] = interact['id'].apply(lambda x: 'RESP'+str(x).zfill(10));\n",
        "\n",
        "            self.post_interaction = interact[['id', 'uid', 'post_id', 'like', 'comment', 'share']];\n",
        "        return self.post_interaction.loc[:];"
      ],
      "metadata": {
        "id": "amcy42f-irKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GenGraph:\n",
        "\n",
        "    sna:MockupSNA03 = None;\n",
        "    def __init__(self):\n",
        "        sna = MockupSNA03();\n",
        "        # sna.set_param( n_like_min=500, n_like_max=1000, n_intrx_min=350, n_intrx_max=780, n_follow_min=750, n_follow_max=1250 );\n",
        "        sna.set_param( n_like_min=350, n_like_max=500, n_intrx_min=225, n_intrx_max=427, n_follow_min=125, n_follow_max=422 );\n",
        "        # sna.init_aff_network(1751);\n",
        "        sna.init_aff_network();\n",
        "        sna.gen_model();\n",
        "        self.sna = sna;\n",
        "        pass;\n",
        "\n",
        "    def get_sna(self) -> MockupSNA03: return self.sna;\n",
        "\n",
        "    def gen_practice01(self):\n",
        "        sna = self.sna;\n",
        "\n",
        "        # Gen edge\n",
        "        posts = sna.get_posts();\n",
        "        interact = sna.get_post_interaction();\n",
        "        interact = interact.set_index('post_id').join(posts.set_index('id'));\n",
        "        interact.reset_index(names=['post_id'], inplace=True);\n",
        "        interact['topic'] = interact['topic']+',ads-engagement';\n",
        "\n",
        "        user_engagement:pd.DataFrame = interact.groupby(['uid', 'page_id'])[['like', 'comment', 'share']].sum().reset_index();\n",
        "        tmp = interact.groupby(['uid', 'page_id'])['topic'].apply(list).reset_index();\n",
        "        user_engagement = user_engagement.set_index(['uid', 'page_id']).join(tmp.set_index(['uid', 'page_id']));\n",
        "        user_engagement.reset_index(names=['uid', 'page_id'], inplace=True);\n",
        "        user_engagement['topic'] = user_engagement['topic'].apply(','.join);\n",
        "        user_engagement['topic'] = user_engagement['topic'].astype(str);\n",
        "        user_engagement['topic'] = user_engagement['topic'].str.split(',');\n",
        "        user_engagement['topic'] = user_engagement['topic'].apply(set)\n",
        "        user_engagement['topic'] = user_engagement['topic'].apply(','.join);\n",
        "        user_engagement['type'] = 'Directed';\n",
        "        user_engagement['weight'] = user_engagement['like']*1 + user_engagement['comment']*2 + user_engagement['share']*2;\n",
        "        user_engagement_total_weight = user_engagement['weight'].sum();\n",
        "        user_engagement['weight'] = user_engagement['weight']*100/ user_engagement_total_weight;\n",
        "        user_engagement.rename(columns={'topic':'linkage', 'uid':'source', 'page_id':'target'}, inplace=True);\n",
        "\n",
        "        users_friends = sna.get_user_x_user();\n",
        "        users_friends['linkage'] = users_friends['linkage'] +',friend';\n",
        "        users_friends['type'] = 'Directed';\n",
        "        users_friends['weight'] = 0.01;\n",
        "\n",
        "        page_propogation = sna.get_user_x_page();\n",
        "        page_propogation.drop(columns=['id'], inplace=True);\n",
        "        page_propogation['linkage'] = 'ads-propogation';\n",
        "        page_propogation['type'] = 'Directed';\n",
        "        page_propogation['weight'] = 0.05;\n",
        "        page_propogation.rename(columns={'page_id':'source', 'uid':'target'},inplace=True);\n",
        "\n",
        "        edge = pd.concat([users_friends, user_engagement, page_propogation]);\n",
        "        edge.to_csv('edge.csv', index=False);\n",
        "\n",
        "        # Gen node\n",
        "        users = sna.get_users();\n",
        "        users['type']='user';\n",
        "        users.rename(columns={'uid':'id'}, inplace=True);\n",
        "        users.drop(columns=['topic', 'topic_p'], inplace=True);\n",
        "\n",
        "        pages = sna.get_pages()\n",
        "        brands = sna.get_brands()\n",
        "        pages = pages.set_index('brand').join(brands[['id','mrkt_value']].set_index('id'));\n",
        "        pages.reset_index(names=['brand'], inplace=True);\n",
        "\n",
        "        node = pd.concat([users, pages]);\n",
        "        node.to_csv('node.csv', index=False);\n",
        "        pass;\n",
        "\n",
        "    def gen_brand_engagement(self):\n",
        "        sna = self.sna;\n",
        "\n",
        "        interact = sna.get_post_interaction();\n",
        "        posts = sna.get_posts();\n",
        "        brands = sna.get_brands()[['id', 'type']];\n",
        "        brands.rename(columns={'type':'brand_type'}, inplace=True);\n",
        "        pages = sna.get_pages()[['id', 'type']];\n",
        "        pages.rename(columns={'type':'page_type'}, inplace=True);\n",
        "\n",
        "        uxu = sna.get_user_x_user();\n",
        "        uxp = sna.get_user_x_page();\n",
        "\n",
        "        # Gen edge\n",
        "        interact['score'] = interact['like'] + 2*interact['comment'] + 2*interact['share'];\n",
        "        interact['score'] = interact['score']/100;\n",
        "        interact.drop(columns=['id', 'like', 'comment', 'share'], inplace=True);\n",
        "\n",
        "        interact = interact.set_index('post_id').join(posts.set_index('id')).reset_index(names=['post_id']);\n",
        "        interact.drop(interact[~interact.brand.isin(brands.id)].index, inplace=True);\n",
        "\n",
        "        interact = interact.set_index('brand').join(brands.set_index('id')).reset_index(names=['brand']);\n",
        "        interact = interact.set_index('page_id').join(pages.set_index('id')).reset_index(names=['page_id']);\n",
        "\n",
        "        ## User-brand engagment\n",
        "        user_brand = interact.groupby(['uid', 'brand', 'brand_type'])['score'].sum().reset_index();\n",
        "        tmp = interact.groupby(['uid', 'brand', 'brand_type'])['topic'].apply(set).reset_index();\n",
        "        tmp['topic'] = tmp['topic'].apply(lambda x: ','.join(x));\n",
        "        user_brand = user_brand.set_index(['uid', 'brand', 'brand_type']).join(\n",
        "                tmp.set_index(['uid', 'brand', 'brand_type'])).reset_index();\n",
        "\n",
        "        user_brand['src_type'] = 'user';\n",
        "        user_brand['type'] = 'undirected';\n",
        "        user_brand['relation'] = 'user-engagement';\n",
        "        user_brand.rename(columns={'uid':'source', 'brand':'target', 'score':'weight', 'brand_type':'tgt_type'}, inplace=True);\n",
        "\n",
        "        ## page-brand engagement\n",
        "        page_brand = interact.groupby(['page_id', 'brand', 'brand_type', 'page_type'])['score'].sum().reset_index();\n",
        "        tmp = interact.groupby(['page_id', 'brand', 'brand_type', 'page_type'])['topic'].apply(set).reset_index();\n",
        "        tmp['topic'] = tmp['topic'].apply(lambda x: ','.join(x));\n",
        "        page_brand = page_brand.set_index(['page_id', 'brand', 'brand_type', 'page_type']).join(\n",
        "                tmp.set_index(['page_id', 'brand', 'brand_type', 'page_type'])).reset_index();\n",
        "        page_brand['type'] = 'undirected';\n",
        "        page_brand['relation'] = 'inflencer-engagement';\n",
        "        page_brand.rename(columns={'page_id':'source', 'brand':'target',\n",
        "                'page_type':'src_type', 'brand_type':'tgt_type', 'score':'weight'}, inplace=True);\n",
        "\n",
        "        ## user-friend relation\n",
        "        uxu.drop(uxu[uxu.linkage=='non-mu-topic'].index, inplace=True);\n",
        "        uxu['src_type'] = 'user';\n",
        "        uxu['tgt_type'] = 'user';\n",
        "        uxu['weight'] = 0.01;\n",
        "        uxu['type'] = 'undirected';\n",
        "        uxu['relation'] = 'user-user';\n",
        "        uxu.rename(columns={'linkage':'topic'},inplace=True);\n",
        "\n",
        "        ## user-page-follow relation\n",
        "        uxp.drop(columns=['id'], inplace=True);\n",
        "        uxp['src_type'] = 'user';\n",
        "        uxp = uxp.set_index('page_id').join(pages.set_index('id')).reset_index(names=['page_id']);\n",
        "        uxp['weight'] = 0.01;\n",
        "        uxp['type'] = 'undirected';\n",
        "        uxp['relation'] = 'user-page';\n",
        "\n",
        "        tmp = interact.groupby(['uid','page_id'])['topic'].apply(set).reset_index();\n",
        "        uxp = uxp.set_index(['uid', 'page_id']).join(tmp.set_index(['uid','page_id'])).reset_index();\n",
        "        uxp.dropna(subset=['topic'],inplace=True);\n",
        "        uxp['topic'] = uxp['topic'].apply(','.join);\n",
        "        uxp.rename(columns={'uid':'source', 'page_id':'target', 'page_type':'tgt_type'},inplace=True);\n",
        "\n",
        "        edge = pd.concat([user_brand, page_brand, uxu, uxp]);\n",
        "        edge.to_csv('edge.csv', index=False);\n",
        "\n",
        "        #Gen node\n",
        "        node = sna.get_users()[['uid']].loc[:];\n",
        "        node['type'] = 'user'\n",
        "        node.rename(columns={'uid':'id'}, inplace=True);\n",
        "        pages.rename(columns={'page_type':'type'},inplace=True);\n",
        "        brands = sna.get_brands();\n",
        "        node = pd.concat([node, pages, brands]);\n",
        "        node.to_csv('node.csv', index=False);\n",
        "        pass;\n",
        "\n",
        "GenGraph().gen_brand_engagement()"
      ],
      "metadata": {
        "id": "k5mEiaalC8bk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}